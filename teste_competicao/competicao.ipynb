{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Modelo de classificação do gênero do filme</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Criação do dataset e definição dos atributos</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<head>\n",
    "    <title><h2><b>Competição - Classificador de Filmes</title>\n",
    "    <meta charset=\"utf-8\"/>\n",
    "</head>\n",
    "<body>\n",
    "Inicialmente efetuou-se a leitura do dataset de treino. O Dataset lido foi armazenado no dataframe df_amostra. Para que pudessemos efetuar\n",
    "o treinamento, os dados dos filmes precisaram passar por uma etapa de tratamento.\n",
    "Como cada filme possui dados de atores, escritores, diretores, ano, popularidade e etc, e muitos destes dados não possuem valor agregado ou\n",
    "mesmo não são relevantes para nosso caso de estudo. Partimos das seguintes premissas para a escolha dos atributosinstancias:\n",
    "\n",
    "- Atores:  muitos atores participam de filmes dentro de um mesmo gênero. Por exemplo: Adan Sandler é conhecido por fazer filmes de comédia. Binarizamos os dados dos atores. Atores cuja presença foi detectada em pelo menos 3 instâncias de filme será considerado um atributo relevante.\n",
    "\n",
    "- Diretor: Este atributo segue a mesma premissa do atributo ator.\n",
    "\n",
    "- Data de estreia: este atributo foi considerado relevante por acreditarmos que cada época possui um tipo de filme que é mais produzido. Exemplo: após 2008 foram produzidos um número muito grande de filmes de ação pela Marvel. Este dado foi tratado de modo a apresentar apenas o ano no dataframe.\n",
    "\n",
    "Tentamos utilizar o parâmetro resumo utilizando ```BagOfWords```, no entanto, devido a quantidade elevada de colunas geradas ocorreu estouro de memória. Portanto, decidimos que iríamos fazer um dataset separado contendo apenas o resumo processado devidamente.\n",
    "\n",
    "Após o tratamento dos atributos para os dois datasets, foram realizados os experimentos.\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/3000\n",
      "1000/3000\n",
      "2000/3000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Vittorio Gassman</th>\n",
       "      <th>Samuel L. Jackson</th>\n",
       "      <th>Cantinflas</th>\n",
       "      <th>Jean-Claude Van Damme</th>\n",
       "      <th>Richard Pryor</th>\n",
       "      <th>Fred Williamson</th>\n",
       "      <th>Renato Pozzetto</th>\n",
       "      <th>Brendan Gleeson</th>\n",
       "      <th>Paul Reubens</th>\n",
       "      <th>William Hurt</th>\n",
       "      <th>...</th>\n",
       "      <th>Jay Chapman</th>\n",
       "      <th>John Woo</th>\n",
       "      <th>Billy Wilder</th>\n",
       "      <th>Robert Altman</th>\n",
       "      <th>Robert Stevenson</th>\n",
       "      <th>Tsui Hark</th>\n",
       "      <th>Juliusz Machulski</th>\n",
       "      <th>id</th>\n",
       "      <th>data_de_estreia</th>\n",
       "      <th>genero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>86295</td>\n",
       "      <td>1981</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>289198</td>\n",
       "      <td>2014</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24382</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>479</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>37712</td>\n",
       "      <td>2001</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52448</td>\n",
       "      <td>1978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26603</td>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45438</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>114060</td>\n",
       "      <td>1958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14030</td>\n",
       "      <td>1969</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Vittorio Gassman Samuel L. Jackson Cantinflas Jean-Claude Van Damme  \\\n",
       "0                   0                 0          0                     0   \n",
       "1                   0                 0          0                     0   \n",
       "2                   1                 0          0                     0   \n",
       "3                   0                 1          0                     0   \n",
       "4                   0                 0          0                     0   \n",
       "...               ...               ...        ...                   ...   \n",
       "2995                0                 0          0                     0   \n",
       "2996                0                 0          0                     0   \n",
       "2997                0                 0          0                     0   \n",
       "2998                0                 0          0                     0   \n",
       "2999                0                 0          0                     0   \n",
       "\n",
       "     Richard Pryor Fred Williamson Renato Pozzetto Brendan Gleeson  \\\n",
       "0                0               0               0               0   \n",
       "1                0               0               0               0   \n",
       "2                0               0               0               0   \n",
       "3                0               0               0               0   \n",
       "4                0               0               0               0   \n",
       "...            ...             ...             ...             ...   \n",
       "2995             0               0               0               0   \n",
       "2996             0               0               0               0   \n",
       "2997             0               0               0               0   \n",
       "2998             0               0               0               0   \n",
       "2999             0               0               0               0   \n",
       "\n",
       "     Paul Reubens William Hurt  ... Jay Chapman John Woo Billy Wilder  \\\n",
       "0               0            0  ...           0        0            0   \n",
       "1               0            0  ...           0        0            0   \n",
       "2               0            0  ...           0        0            0   \n",
       "3               0            0  ...           0        0            0   \n",
       "4               0            0  ...           0        0            0   \n",
       "...           ...          ...  ...         ...      ...          ...   \n",
       "2995            0            0  ...           0        0            0   \n",
       "2996            0            0  ...           0        0            0   \n",
       "2997            0            0  ...           0        0            0   \n",
       "2998            0            0  ...           0        0            0   \n",
       "2999            0            0  ...           0        0            0   \n",
       "\n",
       "     Robert Altman Robert Stevenson Tsui Hark Juliusz Machulski      id  \\\n",
       "0                0                0         0                 0   86295   \n",
       "1                0                0         0                 0  289198   \n",
       "2                0                0         0                 0   24382   \n",
       "3                0                0         0                 0     479   \n",
       "4                0                0         0                 0   37712   \n",
       "...            ...              ...       ...               ...     ...   \n",
       "2995             0                0         0                 0   52448   \n",
       "2996             0                0         0                 0   26603   \n",
       "2997             0                0         0                 0   45438   \n",
       "2998             0                0         0                 0  114060   \n",
       "2999             0                0         0                 0   14030   \n",
       "\n",
       "     data_de_estreia genero  \n",
       "0               1981      2  \n",
       "1               2014      2  \n",
       "2               1958      1  \n",
       "3               2000      2  \n",
       "4               2001      2  \n",
       "...              ...    ...  \n",
       "2995            1978      1  \n",
       "2996            1988      1  \n",
       "2997            2000      1  \n",
       "2998            1958      1  \n",
       "2999            1969      1  \n",
       "\n",
       "[3000 rows x 590 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import optuna\n",
    "import pickle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from base_am.resultado import Fold\n",
    "from base_am.avaliacao import Experimento\n",
    "from base_am.preprocessamento_atributos import BagOfItems, BagOfWords\n",
    "from competicao_am.metodo_competicao import MetodoCompeticao\n",
    "from competicao_am.avaliacao_competicao import *\n",
    "from competicao_am.gerar_resultado_teste import *\n",
    "from competicao_am.preprocessamento_atributos_competicao import *\n",
    "\n",
    "df_amostra = pd.read_csv(\"datasets/movies_amostra.csv\")\n",
    "\n",
    "bag_cast = BagOfItems(min_occur = 4)\n",
    "df = gerar_atributos(df = df_amostra,bag_cast = bag_cast)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>007</th>\n",
       "      <th>009</th>\n",
       "      <th>05pm</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>1000</th>\n",
       "      <th>1001</th>\n",
       "      <th>100th</th>\n",
       "      <th>...</th>\n",
       "      <th>światłem</th>\n",
       "      <th>şehirlere</th>\n",
       "      <th>şimdi</th>\n",
       "      <th>şte</th>\n",
       "      <th>że</th>\n",
       "      <th>życie</th>\n",
       "      <th>życiowe</th>\n",
       "      <th>आव</th>\n",
       "      <th>गल</th>\n",
       "      <th>genero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 18733 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       00  000  007  009  05pm   10  100  1000  1001  100th  ...  światłem  \\\n",
       "0     0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...       0.0   \n",
       "1     0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...       0.0   \n",
       "2     0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...       0.0   \n",
       "3     0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...       0.0   \n",
       "4     0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...       0.0   \n",
       "...   ...  ...  ...  ...   ...  ...  ...   ...   ...    ...  ...       ...   \n",
       "2995  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...       0.0   \n",
       "2996  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...       0.0   \n",
       "2997  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...       0.0   \n",
       "2998  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...       0.0   \n",
       "2999  0.0  0.0  0.0  0.0   0.0  0.0  0.0   0.0   0.0    0.0  ...       0.0   \n",
       "\n",
       "      şehirlere  şimdi  şte   że  życie  życiowe   आव   गल  genero  \n",
       "0           0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0       2  \n",
       "1           0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0       2  \n",
       "2           0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0       1  \n",
       "3           0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0       2  \n",
       "4           0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0       2  \n",
       "...         ...    ...  ...  ...    ...      ...  ...  ...     ...  \n",
       "2995        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0       1  \n",
       "2996        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0       1  \n",
       "2997        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0       1  \n",
       "2998        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0       1  \n",
       "2999        0.0    0.0  0.0  0.0    0.0      0.0  0.0  0.0       1  \n",
       "\n",
       "[3000 rows x 18733 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow = BagOfWords()\n",
    "df_resumo = bow.cria_bow(df_amostra,\"resumo\")\n",
    "df_resumo[\"genero\"] = df[\"genero\"]\n",
    "df_resumo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Experimentação com métodos de classificação</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<body>\n",
    "Com os dados tratados, foram realizados os experimentos e análise dos métodos e métricas. Identificamos o problema como um caso de Classificação. Como métodos avaliados utilizamos:\n",
    "\n",
    "- LinearSVC: implementa um algoritmo de classificação, que encontra uma linha que separa as classes. O parâmetro random_state indica a seed para embaralhar os dados (0 não embaralha). Definimos o valor como 2.\n",
    "\n",
    "- DecisionTreeClassifier: método não paramétrico de aprendizagem supervisionada. O parâmetro min_samples_split indica o número mínimo de amostras necessárias para separar um nó interno enquanto que random_state indica a seed para embaralhar os dados. (ver https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "\n",
    "- RandomForestClassifier: é um estimador que ajusta um número de classificadores de árvores de decisão em sub-amostras do dataset e utiliza  a média para melhorar a precisão da predição e controla o overfitting. O parâmetro n_estimators define o número de árvores, max_features indica o número de features a serem considerados ao procurar a melhor divisão, min_samples_split indica o número mínimo de amostras necessárias para separar um nó interno e random_state indica a seed para embaralhar os dados (2). (ver https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)\n",
    "\n",
    "- AdaBoostClassifier: é um método que combina vários classificadores de baixo desempenho para obter um classificador forte de alta precisão. São atribuídos pesos aos classificadores e o treino é realizado em cada iteração, onde ele tenta fornecer um ajuste excelente, minimizando o erro de treinamento. O parâmetro learning_rate = 1 define a taxa de aprendizado - quanto menor o valor, melhor costuma ser o resultado e maior o tempo.\n",
    "\n",
    "- ExtraTreeClassifier: é um classificador de árvore extremamente aleatório. \"Ao procurar a melhor divisão para separar as amostras de um nó em dois grupos, divisões aleatórias são desenhadas para cada max_features\" e a melhor divisão entre eles é escolhida. Quando max_features é  1, a árvore de decisão é totalmente aleatória (ver https://scikit-learn.org/stable/modules/generated/sklearn.tree.ExtraTreeClassifier.html).\n",
    "\n",
    "- GradientBoostingClassifier: é um algoritmo que combinam modelos de aprendizado de máquina fracos para criar um modelo preditivo forte, como o AdaBoostingClassifier. O default é utilizar decision Tree para fazer o aumento de gradiente. Em cada etapa, nclasses árvores de regressão são ajustadas no gradiente negativo da função de perda de desvio binomial ou multinomial. (ver https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html)\n",
    "    \n",
    "    \n",
    "Após a execução dos experimentos, seguiu-se com a avaliação das métricas para análise dos métodos que obtiveram os melhores desempenhos para o caso de estudo. Com isto feito, os melhores valores de parâmetros foram adotados.\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Análise dos resultados e Conclusão</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nós utilizamos o ```pickle``` para salvar os experimentos no arquivos e se tornar de forma mais rápida a visualização deles (o que pode ser visto abaixo). Além disso criamos um dataframe com as metricas para avaliar o melhor método dentre os 6 que foram experimentados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Métricas</th>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>ExtraTreeClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <th>Linear_SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acuracia_media</td>\n",
       "      <td>0.736333</td>\n",
       "      <td>0.769333</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.708</td>\n",
       "      <td>0.706</td>\n",
       "      <td>0.528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precisao_media</td>\n",
       "      <td>[0.7458742797019504, 0.6742520055995262]</td>\n",
       "      <td>[0.7908376203076495, 0.7257836294405487]</td>\n",
       "      <td>[0.7309806716218554, 0.6869503704516132]</td>\n",
       "      <td>[0.731233544706915, 0.7121367702857169]</td>\n",
       "      <td>[0.7099642115510538, 0.6354948363313293]</td>\n",
       "      <td>[0.49028275256635834, 0.44953110536787816]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revocacao_media</td>\n",
       "      <td>[0.7167264250844403, 0.6120980304245798]</td>\n",
       "      <td>[0.7428210988470315, 0.6578362119838398]</td>\n",
       "      <td>[0.737950933018791, 0.5654599943099177]</td>\n",
       "      <td>[0.6771310423218238, 0.4899716282843781]</td>\n",
       "      <td>[0.6662994342130661, 0.6011122569812678]</td>\n",
       "      <td>[0.3230559482960289, 0.6884491100455199]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1_por_classe_media</td>\n",
       "      <td>[0.7189933116660747, 0.6280867542830515]</td>\n",
       "      <td>[0.7509673910363566, 0.6757067340845786]</td>\n",
       "      <td>[0.7216312604203111, 0.5969589679997709]</td>\n",
       "      <td>[0.6406074012537104, 0.49045181364192986]</td>\n",
       "      <td>[0.6722842565956512, 0.6034784929624104]</td>\n",
       "      <td>[0.36970999070973676, 0.5280902721761584]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Macro F1</td>\n",
       "      <td>0.67354</td>\n",
       "      <td>0.713337</td>\n",
       "      <td>0.659295</td>\n",
       "      <td>0.56553</td>\n",
       "      <td>0.637881</td>\n",
       "      <td>0.4489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Métricas                GradientBoostingClassifier  \\\n",
       "0       acuracia_media                                  0.736333   \n",
       "1       precisao_media  [0.7458742797019504, 0.6742520055995262]   \n",
       "2      revocacao_media  [0.7167264250844403, 0.6120980304245798]   \n",
       "3  f1_por_classe_media  [0.7189933116660747, 0.6280867542830515]   \n",
       "4             Macro F1                                   0.67354   \n",
       "\n",
       "                               RandomForest  \\\n",
       "0                                  0.769333   \n",
       "1  [0.7908376203076495, 0.7257836294405487]   \n",
       "2  [0.7428210988470315, 0.6578362119838398]   \n",
       "3  [0.7509673910363566, 0.6757067340845786]   \n",
       "4                                  0.713337   \n",
       "\n",
       "                        ExtraTreeClassifier  \\\n",
       "0                                     0.733   \n",
       "1  [0.7309806716218554, 0.6869503704516132]   \n",
       "2   [0.737950933018791, 0.5654599943099177]   \n",
       "3  [0.7216312604203111, 0.5969589679997709]   \n",
       "4                                  0.659295   \n",
       "\n",
       "                          AdaBoostClassifier  \\\n",
       "0                                      0.708   \n",
       "1    [0.731233544706915, 0.7121367702857169]   \n",
       "2   [0.6771310423218238, 0.4899716282843781]   \n",
       "3  [0.6406074012537104, 0.49045181364192986]   \n",
       "4                                    0.56553   \n",
       "\n",
       "                     DecisionTreeClassifier  \\\n",
       "0                                     0.706   \n",
       "1  [0.7099642115510538, 0.6354948363313293]   \n",
       "2  [0.6662994342130661, 0.6011122569812678]   \n",
       "3  [0.6722842565956512, 0.6034784929624104]   \n",
       "4                                  0.637881   \n",
       "\n",
       "                                   Linear_SVC  \n",
       "0                                       0.528  \n",
       "1  [0.49028275256635834, 0.44953110536787816]  \n",
       "2    [0.3230559482960289, 0.6884491100455199]  \n",
       "3   [0.36970999070973676, 0.5280902721761584]  \n",
       "4                                      0.4489  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#caso queira ver nossos resultados para os experimentos retire o comentario\n",
    "gerar_resultados_df_cast()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando um dataset formado unicamente pelo elenco, diretores e a data de estreia do filme obtivemos os resultados acima. Pela análise dos resultados das métricas, observamos que o método que obteve os melhores resultados para a métrica Macro F1 foi o Random Forest. A Macro F1 apresenta a média harmônica entre a revocação e a precisão, indicando um valor balanceado para as classes. \n",
    "Nossos resultados indicaram uma revocação um tanto desequilibrada entre as classes na maioria dos métodos, ou seja, uma classe tem maior facilidade de ser prevista que a outra, possivelmente em decorrência da existência de um número maior de instâncias pertencentes a uma classe em relaçao a outra, criando um viés de tendência.\n",
    "Lembrando que foram realizadas 30 tentativas para todos os métodos utilizando o algoritmo TPE sampler para escolher parâmetros que tenham resultados melhores. Aqueles que utilizam learning_rate, utilizamos valores de 0 a 1, min_samples_split de 0 a 0,5, max_features de 0 a 0,5 e o número de árvores de 1 a 100. Além disso, o método LinearSVC utilizou um valor C variando de 10^-5 a 10^5.\n",
    "Sendo assim, para este dataset, o melhor metódo foi o RandomForest. No entanto, fizemos uma segunda rodada de testes utilizando um dataset contendo apenas o resumo (utilizando da classe BagOfWords). Para tratar melhor os dados do resumo, removemos as palavras irrelevantes como artigos, pronomes, advérbios, entre outros. Para isso fizemos uma pesquisa procurando o maior conjunto possível de palavras desse tipo no idioma inglês utilizando o site: https://countwordsfree.com/stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Métricas</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>Linear_SVC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acuracia_media_Folds</td>\n",
       "      <td>0.808667</td>\n",
       "      <td>0.809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precisao_media_Folds</td>\n",
       "      <td>[0.82232642357649, 0.7579140840446128]</td>\n",
       "      <td>[0.8143701340475534, 0.7708187347089507]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revocacao_media_Folds</td>\n",
       "      <td>[0.7900559293665496, 0.7685206826862406]</td>\n",
       "      <td>[0.801722333765823, 0.7359738164817508]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1_por_classe_media_Folds</td>\n",
       "      <td>[0.8046183887928979, 0.7606196762470152]</td>\n",
       "      <td>[0.8049844199168792, 0.7499030211938327]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Macro F1</td>\n",
       "      <td>0.782619</td>\n",
       "      <td>0.777444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Métricas                        AdaBoostClassifier  \\\n",
       "0       acuracia_media_Folds                                  0.808667   \n",
       "1       precisao_media_Folds    [0.82232642357649, 0.7579140840446128]   \n",
       "2      revocacao_media_Folds  [0.7900559293665496, 0.7685206826862406]   \n",
       "3  f1_por_classe_media_Folds  [0.8046183887928979, 0.7606196762470152]   \n",
       "4                   Macro F1                                  0.782619   \n",
       "\n",
       "                                 Linear_SVC  \n",
       "0                                     0.809  \n",
       "1  [0.8143701340475534, 0.7708187347089507]  \n",
       "2   [0.801722333765823, 0.7359738164817508]  \n",
       "3  [0.8049844199168792, 0.7499030211938327]  \n",
       "4                                  0.777444  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#caso queira ver nossos resultados para os experimentos retire o comentario\n",
    "gerar_resultados_df_resumo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observamos que os resultados obtidos com o dataset composto pelo resumo foram melhores do que o primeiro dataset testado. As métricas de precisão para a classe Comedy e a acurácia foram superiores ao método RandomForest nos métodos LinearSVC e AdaBoosting. Sendo assim optou-se pelo método AdaBoosting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após decidirmos sobre o método a ser adotado (Ada Boosting utilizando como base_estimator o LinearSVC), avaliamos dentro do método as melhores métricas. Para isso, a cada iteração (cada fold), avaliamos o valor da métrica Macro F1. Com isto, a iteração com o maior valor é avaliada separadamente e escolhemos os parâmetros da trial com os melhores resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Analise de resultados da segunda rodada</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<html>\n",
    "<body>\n",
    "Após os resultado da primeira rodada, optamos por realizar uma segunda análise dos métodos e dos atributos de interesse. Mais uma vez, com base nos nossos resultados, o resumo se mostrou a melhor opção. Partindo desse ponto analisamos como seria o resultado se uníssemos dois métodos distintos, a saber: AdaBoost Classifier e Linear SVC. Para tal, adotamos o seguinte critério:\n",
    "    \n",
    "- Caso o AdaBoost Classifier classificasse o filme como comédia, este seria o valor adotado. Se a classificação fosse ação adotaríamos o LinearSVC.\n",
    "\n",
    "Esta foi uma tentativa de minizarmos os valores de revocação mais baixos do AdaBoost para ação. No entanto não obtivemos um resultado satisfatório. Muito pelo contrário os resultados ficaram abaixo do esperado. Com isso, resolvemos analisar os paramêtros obtidos pelo método AdaBoost, que fora escolhido como melhor na primeira rodada. Dessa forma, analizamos o best_params de cada fold e fixamos este valor na OtimizacaoObjetivo. Notamos que apesar do fold 5 ter tido o melhor Macro F1, ao rodarmos o teste, os resultados foram menores do que os resultados dos demais folds. Então optamos pelo fold 2 que apesar de ter tido um Macro F1 um pouco menor que o do fold 5, no teste obteve um resultado mais adequado.\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Métricas</th>\n",
       "      <th>AdaBoostClassifier e Linear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>acuracia_media_Folds</td>\n",
       "      <td>0.793333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>precisao_media_Folds</td>\n",
       "      <td>[0.8305593506288927, 0.7128051262624142]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>revocacao_media_Folds</td>\n",
       "      <td>[0.7487305225390936, 0.7980923485988489]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>f1_por_classe_media_Folds</td>\n",
       "      <td>[0.7862362000382991, 0.752676321435355]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Macro F1</td>\n",
       "      <td>0.769456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Métricas               AdaBoostClassifier e Linear\n",
       "0       acuracia_media_Folds                                  0.793333\n",
       "1       precisao_media_Folds  [0.8305593506288927, 0.7128051262624142]\n",
       "2      revocacao_media_Folds  [0.7487305225390936, 0.7980923485988489]\n",
       "3  f1_por_classe_media_Folds   [0.7862362000382991, 0.752676321435355]\n",
       "4                   Macro F1                                  0.769456"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "exp_adaElinear = pickle.load( open( \"resultados.exp_AdaBoostELinear_resumo_1.p\", \"rb\" ) )\n",
    "acuracia_media_AdaBoost, precisao_media_AdaBoost, revocacao_media_AdaBoost, f1_classe_media_AdaBoost = Calculos.calcula_indices_importantes(exp_adaElinear.resultados)\n",
    "df = pd.DataFrame({\n",
    "    'Métricas' : [\"acuracia_media_Folds\", \"precisao_media_Folds\", \"revocacao_media_Folds\", \"f1_por_classe_media_Folds\", \"Macro F1\"],\n",
    "    'AdaBoostClassifier e Linear' : [acuracia_media_AdaBoost, precisao_media_AdaBoost, revocacao_media_AdaBoost, f1_classe_media_AdaBoost, exp_adaElinear.macro_f1_avg]\n",
    "})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Aplicação do modelo em um dataset de testes</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para gerar a saída do resultado da amostra de teste iniciamente devemos ler o arquivo .csv, por intermédio da função ```pd.read_csv```. Após isso, é chamada a função ```gerar_saida_teste``` recebendo como parâmetros o dataset e a classe que queremos prever além do número do nosso grupo (no caso o grupo 4). No escopo da função é lido o dataset utilizado para o treino. Depois disso, foi realizado o processamento do resumo utilizando a classe BagOfWords para o dataset de treino e o de testes. Foi instanciado um objeto da classe MetodoCompeticao passando como parâmetro o melhor método de classificação que obtivemos após a realização dos experimentos e com seu parâmetros já fixados (o AdaBoosting). Utilizando o dataset processado do treino e a classe ```genero``` foi feito o ```fit``` e obtido um modelo. Com base nesse modelo foi feito o ```predict``` utilizando o dataset processado de testes. Por fim o vetor de predições foi processado utilizando um dicionário e passado para o arquivo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File datasets/movies_amostra_teste_2.csv does not exist: 'datasets/movies_amostra_teste_2.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1e3b589798d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf_amostra_teste\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"datasets/movies_amostra_teste_2.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgerar_saida_teste\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_amostra_teste\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"genero\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    674\u001b[0m         )\n\u001b[0;32m    675\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 676\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    677\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    678\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    446\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1113\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1114\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1116\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1889\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1891\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1892\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1893\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File datasets/movies_amostra_teste_2.csv does not exist: 'datasets/movies_amostra_teste_2.csv'"
     ]
    }
   ],
   "source": [
    "df_amostra_teste = pd.read_csv(\"datasets/movies_amostra_teste_2.csv\")\n",
    "gerar_saida_teste(df_amostra_teste,\"genero\",4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
